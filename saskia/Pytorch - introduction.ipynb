{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"slide1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"firmen.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"torch.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually one uses PyTorch either as:\n",
    "\n",
    "    A replacement for numpy to use the power of GPUs.\n",
    "    a deep learning research platform that provides maximum flexibility and speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a python package that provides two high-level features:\n",
    "\n",
    "- Tensor computation (like numpy) with strong GPU acceleration\n",
    "- Deep Neural Networks built on a tape-based autodiff system\n",
    "\n",
    "You can reuse your favorite python packages such as numpy, scipy and Cython to extend PyTorch when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PyTorch, we use a technique called Reverse-mode auto-differentiation, which allows you to change the way your network behaves arbitrarily with zero lag or overhead. Our inspiration comes from several research papers on this topic, as well as current and past work such as autograd, autograd, Chainer, etc.\n",
    "\n",
    "<img src=\"graph.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"package.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use numpy, then you have used Tensors (a.k.a ndarray).\n",
    "\n",
    "<img src=\"tensor_illustration.png\">\n",
    "\n",
    "PyTorch provides Tensors that can live either on the CPU or the GPU, and accelerate compute by a huge amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting Regeln siehe: http://pytorch.org/docs/master/notes/broadcasting.html\n",
    "\n",
    "Two tensors are “broadcastable” if the following rules hold:\n",
    "\n",
    "- Each tensor has at least one dimension.\n",
    "- When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensoren\n",
    "\n",
    "PyTorch Tensors verhalten sich sehr ähnlich wie numpy.ndarrays\n",
    "\n",
    "torch.Tensor is an alias for the default tensor type (torch.FloatTensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-38 *\n",
      "       [[ 8.5074,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8651,  0.7539,  0.0723],\n",
      "        [ 0.7613,  0.0187,  0.1211],\n",
      "        [ 0.1692,  0.0774,  0.2578],\n",
      "        [ 0.0809,  0.6122,  0.1613],\n",
      "        [ 0.1066,  0.1079,  0.4657]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9805],\n",
      "        [ 0.8377],\n",
      "        [ 0.8445],\n",
      "        [ 0.6839],\n",
      "        [ 0.3640]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8482,  0.7391,  0.0709],\n",
      "        [ 0.6378,  0.0157,  0.1014],\n",
      "        [ 0.1429,  0.0654,  0.2177],\n",
      "        [ 0.0554,  0.4186,  0.1103],\n",
      "        [ 0.0388,  0.0393,  0.1695]])\n"
     ]
    }
   ],
   "source": [
    "z = y * x \n",
    "print (z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "a.pow(2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensor.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1],\n",
      "        [ 2,  3]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones((2,), dtype=torch.int8)\n",
    "data = [[0, 1], [2, 3]]\n",
    "print(tensor.new_tensor(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd\n",
    "\n",
    "- Automatische Ableitungen\n",
    "- Keine Session - der Code bestimmt den Graphen (define-by-run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "\n",
    "![](http://pytorch.org/tutorials/_images/Variable.png)\n",
    "\n",
    "- Wrapper für Tensoren\n",
    "- zentrale Schnittstelle zu pyTorch\n",
    "- hält Methoden für die Bearbeitung der Gradienten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.autograd.Variable(torch.ones(2, 2), requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.,  3.],\n",
      "        [ 3.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "f = x + 2\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronale Netzwerke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [```torch.nn```](http://pytorch.org/docs/master/nn.html)\n",
    "- ```nn.Module```: \n",
    "    - Basisklasse aller Neuronalen Netzwerke\n",
    "- ```nn.Parameter```: \n",
    "    - Ähnlich wie ```autograd.Variable```, registriert sich automatisch innerhalb einer von ```nn.Module``` erbenden Klasse\n",
    "    - Alle definierten Parameter können über das Attribut ```net.parameters``` ausgegeben werden\n",
    "- ```autograd.Function```: \n",
    "    - Implementierung der Vorwärts-Pfade im NN. \n",
    "    - Über die Registrierung von ```nn.Variable```  in F representiert diese mindestens 1 Knoten im Graphen des NN\n",
    "    - Hier wird der Pfad und die Werte gespeichert um Backpropagation durchführen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
